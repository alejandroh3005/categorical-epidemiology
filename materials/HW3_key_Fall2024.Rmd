---
title: "BIOST/EPI 536 Homework 3 Solutions"
subtitle: Autumn 2024
output:
  pdf_document: default
---

```{r,include = FALSE, appendix = TRUE}
# Global parameters controlling the formats of output file
# echo = FALSE prevents code, but not the results from appearing in the output file.
# warning = FALSE prevents messages that are generated by code from appearing
# message = FALSE prevents warnings that are generated by code from appearing
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
library(kableExtra) # controlling appearances of rmarkdown tables
library(tableone) # an useful package to generate descriptive tables
library(Hmisc) # mainly used for its "label" function
library(dagR) # draw DAG
library(sandwich)
library(ggplot2)
library(tidyr)
library(dplyr)
```

1.  Your team has conducted a case-control study to examine the evidence that a (binary) exposure affects a disease, and you have analyzed study data.  You are beginning to write a scientific article on your findings.  The first table in your article will describe study participants by sharing descriptive statistics for key variables.  How would you construct your table?  Specifically, would you compute and report descriptive statistics on the whole sample (no stratification)?  Or would you stratify on some variable and, if so, what variable?  Write a short paragraph to explain your choice.
If it helps you to be more concrete, assume that D is a type of cancer, the exposure is a genetic variant, and the hypothesis is that having one or more copies of the genetic variant increases a person’s risk of the cancer.


**Answer: **

Sampling subjects for a case-control study conditions on disease status. A case-control study essentially involves two samples, a sample of cases and a sample of controls. Therefore, it makes the most sense to show these two samples in the table of descriptive statistics by making the table stratified on disease status. This can help assess, for example, whether cases and controls differ substantially on factors other than disease status. Are controls much younger than cases? Are cases more often diabetic than controls? By stratifying the table on case/control status, one can make some assessments that could help with interpretation of study results, or help in comparing study results to the results of related studies. As stated in HW1 Q1, a column with p-values is not appropriate here either because p-values are inferential quantities used to infer what is true in a population from a sample, let alone cases and controls may come from different populations if controls are not properly sampled. 

**Comment: ** It would not be helpful to stratify the table of descriptive statistics on the exposure when data come from a case-control study design. It is difficult or impossible to make much sense of the descriptive statistics if this is done, since each exposure group is a typically a different mix of the case sample and the control sample. For the same reason, it would be not helpful to include a column for the overall sample (cases + controls). 


2.  Before it was understood that polycystic kidney disease (PKD) is a genetic disorder, Dr. Ott hypothesized that lead poisoning was a cause of PKD.  In planning a study to collect evidence to study a possible effect of lead poisoning on PKD, Dr. Ott wonders whether glomerular filtration rate (GFR) is a confounder because prior work showed that GFR is associated with both lead poisoning and PKD.  Suppose, in truth, lead poisoning is a cause of renal failure (the kidneys don't work as well as they should), affecting GFR.  Similarly, PKD is a cause of kidney failure.  Draw a DAG summarizing the information presented.  Should Dr. Ott treat GFR as a confounder?

**Answer: **

Consider the DAG in Figure 1. Removing all edges emanating from the exposure (Lead) we don't have any unblocked paths from Lead to PKD, meaning GFR is not a confounder. Note that GFR is a collider on the path Lead-GFR-PKD. 

```{r, include = FALSE, appendix = TRUE}
 Dag_Q2 <- dag.init(cov = c(1), #We add a standard covariate
                  arcs = c(0,1, #Line from exposure to covariate
                           -1,1), #Line from covariate to outcome
                  x.name = "Lead", #Name of exposure
                  y.name = "PKD", #Name of Outcome
                  cov.names = c("GFR"),
                  symbols = c("Lead","GFR","PKD") #How the names will show in the DAG
                  #xgap=.12
                  )
 
Dag_Q2v2 <- dag.init(cov = c(1,2), #We add standard covariates
                  arcs = c(0,1, #Line from exposure to covariate 1
                           1,2,  #Line from covariate 1 to covariate 2
                           -1,1), #Line from covariate 1to outcome
                  x.name = "Lead", #Name of exposure
                  y.name = "PKD", #Name of Outcome
                  cov.names = c("RF", "GFR"),
                  symbols = c("Lead","RF", "GFR","PKD") #How the names will show in the DAG
                  #xgap=.12
                  )

```


```{r, echo=FALSE,warning=FALSE,message=FALSE,error=FALSE,results='hide',fig.cap=" DAG describing the lead poisoning - glomerular filtration rate - polycystic kidney disease causal relationship", fig.width=5, fig.height=3, appendix = TRUE}
par(mar=rep(.1,4))
dag.draw(Dag_Q2, legend = FALSE)
```

Alternatively, consider the DAG in Figure 2, where we include renal failure (RF) as a node. We don't have any unblocked backdoor paths from Lead to PKD after removing edges emanating from Lead so again, GFR is not a confounder. 

```{r, echo=FALSE,warning=FALSE,message=FALSE,error=FALSE,results='hide',fig.cap=" DAG describing the lead poisoning - renal failure - glomerular filtration rate - polycystic kidney disease causal relationship", fig.width=5, fig.height=2, appendix = TRUE}
par(mar=rep(.1,4))
dag.draw(Dag_Q2v2, legend = FALSE)
```

3.  Assume that P(D) in a population is 10%.  Investigators plan to conduct a case-control study (unmatched) to study associations between D and a binary exposure E and also collect data on a binary covariate C.  Their analysis model will be logit(p) = $\beta_0$ +  $\beta_1$ C  + $\beta_E$ E + $\beta$ * C$\times$E .  

A.  The investigators will sample an equal number of cases and controls – 1:1 sampling.  What is $\pi$, the ratio of sampling probabilities?  What is the expected value of $\hat{\beta_0}$?  Write the expected value in terms of population parameters.

**Answer:**

In the population, there are 9 controls for every 1 case.  Since the study will sample the same number of cases and controls, one can reason that a control has 1/9 the chance of being sampled than a case, so $\pi=9$.

An alternative argument employs Bayes' rule. In the sample there is the same number of cases and controls, so $P(D=1 \mid Z = 1) = P(D=0 \mid Z=1) = 0.5$. By applying the Baye's theorem we obtain: 

$$\pi = \frac{P[Z=1 \mid D=1]}{P[Z=1 \mid D=0]} = \frac{\frac{P(D=1 \mid Z=1) P(Z=1)}{p(D=1)}}{\frac{P(D=0 \mid Z=1) P(Z=1)}{p(D=0)}} = \frac{P(D=1 \mid Z=1) }{P(D=0 \mid Z=1)} \frac{p(D=0)}{p(D=1)} = \frac{0.5 \times 0.9}{0.5 \times 0.1} = 9.$$

The expected value of $\hat{\beta_0}$ is the sum of the logit of the probability of disease given $E = 0$ and $C = 0$ (logit $P[D \mid E=0, C = 0]$) and the log of the ratio of sampling probabilities ($\pi$), meaning: 

$$\mathbb{E}\left[\hat{\beta_0}\right] = \log (9) + \text{logit}(P[D \mid E=0, C = 0]).$$

B.  For every sampled case, investigators will sample 9 controls – 1:9 sampling.  What is $\pi$, the ratio of sampling probabilities?  What is the expected value of $\hat{\beta}_0$?  Write the expected value in terms of population parameters.  Comment on whether this expected value surprises you, or if you can make sense of the difference from A.

**Answer: **

Since there are 9 controls for every 1 case in the population, and 9 controls will be sampled for every case sampled, we can reason that $\pi=1$.  Alternatively, since now we have a 1:9 sampling, we have $P(D=1 \mid Z = 1) = 0.1$ and $P(D=0 \mid Z=1) = 0.9$. Now we obtain


$$\pi = \frac{P[Z=1 \mid D=1]}{P[Z=1 \mid D=0]} = \frac{\frac{P(D=1 \mid Z=1) P(Z=1)}{p(D=1)}}{\frac{P(D=0 \mid Z=1) P(Z=1)}{p(D=0)}} = \frac{P(D=1 \mid Z=1) }{P(D=0 \mid Z=1)} \frac{p(D=0)}{p(D=1)} = \frac{0.1 \times 0.9}{0.9 \times 0.1} = 1,$$

which implies 


$$\mathbb{E}\left[\hat{\beta_0}\right] = \log (1) + \text{logit}(P[D \mid E=0, C = 0]) = \text{logit}(P[D \mid E=0, C = 0]).$$

This expected value coincides with the  parameter of the population as if this were a cohort study instead of a case-control study.  Thus, it is a bit misleading to call this a case-control study, since the essence of a case-control study is oversampling cases relative to the population.  Sampling cases and controls to match their proportions in the population  effectively makes the sampling scheme  equivalent to a cohort sampling, and the intercept parameter can be interpreted in the same way it is interpreted in a cohort study. 

**Comment: ** Doing this in case-control studies in reality is generally not possible, since we usually do not know a priori the representation of cases in the population, and it is not practical or worthwhile to sample many controls per case.  Moreover, even if we do know the representation of cases in the population, we could use that information (if we wanted) to calculate $\pi$ and provide an interpretation of a model intercept, even with 1:1 sampling.  Still, the model intercept is rarely of scientific interest, so we might not bother.

\newpage

4.  Suppose you have data for 90 people on a continuous explanatory variable X and a binary outcome D, summarized in the following table:

\begin{tabular}{|c|c|c|}
\hline
X & D   &Frequency (number of people) \\ \hline
0 & no  & 20                                                                      \\ \hline
0 & yes & 10                                                                      \\ \hline
1 & no  & 15                                                                      \\ \hline
1 & yes & 15                                                                      \\ \hline
2 & no  & 10                                                                      \\ \hline
2 & yes & 20                                                                      \\ \hline
\end{tabular}

A.  (part A is optional – you are encouraged to do Part A, but you can receive full credit without submitting part A) Although it is not very informative, make a scatterplot of X and D (coded as no=0 and yes=1).  Do your best to make the scatterplot informative (for example, “jitter” to show overlapping points).  Also, make the plot comparable with the plot you will make for Q6A (e.g. same axes scales).

**Answer: **

```{r,echo=FALSE, cap.fig = "Scatterplot of D against X.", fig.width= 5, fig.height= 5, appendix = TRUE}

Data_Q4  <- data.frame(
  X = c(0,0,1,1,2,2),
  D = c(0,1,0,1,0,1)
)

frequency <- c(20,10,15,15,10,20)

Data_Q4_long <- uncount(Data_Q4, frequency)

plot(jitter(Data_Q4_long$X,amount=0.2),jitter(Data_Q4_long$D,amount = 0.2),
     xlab= "X", ylab = "D")

```


B.  Fit a simple logistic regression model of D on X.  Write the fitted model.

**Answer: **

```{r,include= FALSE, appendix = TRUE}
  Model_4B = glm(D ~ X,data = Data_Q4_long, family = "binomial")

  Coefficients = round(summary(Model_4B)$coef[,1], digits = 3)
```

The simple logistic fitted model is $\text{logit} \left[P(D = 1 \mid X) \right] =$ `r Coefficients[1]` + `r Coefficients[2]`X, or alternatively $P(D = 1 \mid X) = \text{expit}(-0.69 + 0.69 X)$ where $\text{expit}(u) = \frac{\exp(u)}{\exp(u) + 1}.$

C.	According to the fitted model, what is the probability of D for individuals with X=0?  Why does this make sense?

**Answer: **

According to the fitted model, the probability of $D$ when $X = 0$ is given by

$$P(D = 1 \mid X=0) = \frac{\exp(-0.693)}{\exp(-0.693) + 1} = 0.333 $$

This makes sense because in the table we observe 10 diseased people in the group $X=0$, which has 30 people in total.

D.  According to the fitted model, what is the probability of D for individuals with X=1?  Why does this make sense?

**Answer: **

According to the fitted model, the probability of $D$ when $X = 1$ is given by

$$P(D = 1 \mid X=1) = \frac{\exp(-0.693 + 0.693)}{\exp(-0.693 + 0.693) + 1} = 0.5$$

This makes sense since, out of the 30 people with $X= 1$, exactly 15 are diseased, which is half in this population. 

E.  According to the fitted model, what is the probability of D for individuals with X=2?  Why does this make sense?

According to the fitted model, the probability of $D$ when $X = 2$ is given by

$$P(D = 1 \mid X=2) = \frac{\exp(-0.693 + 0.693 \times 2)}{\exp(-0.693 + 0.693\times 2) + 1} = 0.667$$

This makes sense since, out of the 30 people with $X= 2$, exactly 20 are diseased, which is $2/3$ of this population. 

F.  For each of $X=0,1,2$, estimate $p$, the probability of $D$, using the table above (not the logistic model).  Complete the following table:

\begin{tabular}{|l|l|l|l|}
\hline
X & p,   probability of D         & odds of   D   & log (odds of D) = logit (p) \\ \hline
0 & &  &                     \\ \hline
1 & & &                           \\ \hline
2 & &  &                     \\ \hline
\end{tabular}

**Answer: ** Using the values of the table directly we obtain:

\begin{tabular}{|l|l|l|l|}
\hline
X & p,   probability of D         & odds of   D   & log (odds of D) = logit (p) \\ \hline
0 & 10/30 = 1/3 & 1/2 & -0.693                      \\ \hline
1 & 15/30 = 1/2 & 1             & 0                           \\ \hline
2 & 20/30 = 2/3 & 2             & 0.693                       \\ \hline
\end{tabular}

\newpage

G.  Plot logit(p) against X.  What do you notice?

**Answer: ** Observing Figure 3, we find the three points lie on the line described by the fitted model in part B.

```{r, echo = FALSE, fig.width= 5, fig.height=5, fig.cap="Plot of logit(p) against X.", appendix = TRUE}

plot(c(0,1,2), c(-0.693, 0 , 0.693), xlab = "X", ylab = "logit(p)")
abline(a=-0.693, b=0.693)

```

\newpage

\newpage

5. Suppose you have data for 900 people on a continuous explanatory variable X and a binary outcome D, summarized in the following table:

\begin{tabular}{|c|c|c|}
\hline
X & D   &Frequency (number of people) \\ \hline
0 & no  & 200                                                                      \\ \hline
0 & yes & 100                                                                      \\ \hline
1 & no  & 150                                                                      \\ \hline
1 & yes & 150                                                                      \\ \hline
2 & no  & 100                                                                      \\ \hline
2 & yes & 200                                                                      \\ \hline
\end{tabular}

Fit a simple logistic model to these data.  Compare and contrast the results with your results from Q4.  Your comparison should include regression parameter estimates, standard errors, and confidence intervals.

**Answer: **

The results are listed in Table 1. The estimates for the intercept and coefficient of X are the same. However, the corresponding estimated SEs are smaller for the model in question 5 compared to question 4. This also leads to narrower CIs in the model for question 5. These results make sense, since we have larger sample size in question 5, which leads to higher precision. 

```{r, include=FALSE, appendix = TRUE}
 #-----------For model in Question 4-----------------------

Estimate_Q4 <-  summary(Model_4B)$coefficients[,1]

SE_Q4<- sqrt(diag(vcovHC(Model_4B,type ="HC0"))) #Sandwich (robust) standard errors

CI_low_Q4 <- Estimate_Q4 + SE_Q4 * (-1.96) 

CI_high_Q4 <- Estimate_Q4 + SE_Q4 * (1.96) 

#------------For Question 5 ------------------------------
Data_Q5 <-  data.frame(
  X = c(0,0,1,1,2,2),
  D = c(0,1,0,1,0,1)
)

frequency <- c(200,100,150,150,100,200)

Data_Q5_long <- uncount(Data_Q5, frequency)

 Model_5 = glm(D ~ X,data = Data_Q5_long, family = "binomial")
 
Estimate_Q5 <-  summary(Model_5)$coefficients[,1]

SE_Q5<- sqrt(diag(vcovHC(Model_5,type ="HC0"))) #Sandwich (robust) standard errors

CI_low_Q5 <- Estimate_Q5 + SE_Q5 * (-1.96) 

CI_high_Q5 <- Estimate_Q5 + SE_Q5 * (1.96) 

#----------Table of comparison----------------------------

tbl5 = data.frame(I_coef = round(c(Estimate_Q4[1],Estimate_Q5[1]),digits = 3), 
    I_SE= round(c(SE_Q4[1],SE_Q5[1]),digits = 3), 
    I_CI = paste("(",round(c(CI_low_Q4[1],CI_low_Q5[1]),digits = 3),
", ",round(c(CI_high_Q4[1],CI_high_Q5[1]), digits = 3),
")",sep=""),
    I_coef = round(c(Estimate_Q4[2],Estimate_Q5[2]),digits = 3), 
    I_SE= round(c(SE_Q4[2],SE_Q5[2]),digits = 3), 
    I_CI = paste("(",round(c(CI_low_Q4[2],CI_low_Q5[2]),digits = 3),
", ",round(c(CI_high_Q4[2],CI_high_Q5[2]), digits = 3),
")",sep=""))

colnames(tbl5) = c("Coefficient","SE","95% CI","Coefficient"
                   ,"SE","95% CI")
rownames(tbl5) = c("Model in Q4","Model in Q5")

```

```{r, echo=FALSE, appendix = TRUE}
#The nice printing of the table only works when knitting into pdf or HTML
kable(tbl5, format = 'latex', align = 'c', vline = '',
  booktabs = TRUE,
  caption = "Comparison between the fitted model in question 4 and the fitted model in question 5",
  linesep = '') %>% 
  kable_styling(latex_options = "hold_position") %>%
  add_header_above(c(" " = 1, "Intercept" = 3, 
                     "Covariate X" = 3), bold = TRUE) %>%
  footnote(general = 'SEs were calculated based on robust standard errors')
```



6. Suppose you have data for 150 people on an explanatory, continuous variable X and a binary outcome D, summarized in the following table:

\begin{tabular}{|c|c|c|}
\hline
X  & D   & Frequency (number of people) \\ \hline
-1 & no  & 30                           \\ \hline
0  & no  & 20                           \\ \hline
0  & yes & 10                           \\ \hline
1  & no  & 15                           \\ \hline
1  & yes & 15                           \\ \hline
2  & no  & 10                           \\ \hline
2  & yes & 20                           \\ \hline
3  & yes & 30                           \\ \hline
\end{tabular}

\newpage

A.  (part A is optional – you are encouraged to do Part A, but you can receive full credit without submitting part A) Although it is not very informative, make a scatterplot of X and D (using standard 0/1 coding as in Q4).  Do your best to make the scatterplot informative (for example, “jitter” to show overlapping points).  Also, make your plot comparable with the plot from Q4A.

```{r,echo=FALSE, cap.fig = "Scatterplot of D against X.", fig.width= 5, fig.height= 5, appendix = TRUE}
Data_Q6  <- data.frame(
  X = c(-1,0,0,1,1,2,2,3),
  D = c(0,0,1,0,1,0,1,1)
)

frequency <- c(30,20,10,15,15,10,20,30)

Data_Q6_long <- uncount(Data_Q6, frequency)

plot(jitter(Data_Q6_long$X,amount=0.2),jitter(Data_Q6_long$D,amount = 0.2),
     xlab= "X", ylab = "D")

```


B.  Fit a simple logistic regression model of D on X.  Write the fitted model.
Fit a simple logistic regression model of D on X.  Write the fitted model.

**Answer: **

```{r,include= FALSE, appendix = TRUE}
  Model_6B = glm(D ~ X,data = Data_Q6_long, family = "binomial")

  Coefficients = round(summary(Model_6B)$coef[,1], digits = 3)
```

The simple logistic fitted model is $\text{logit} \left[P(D = 1 \mid X) \right] =$ `r Coefficients[1]` + `r Coefficients[2]`X, or alternatively $P(D = 1 \mid X) = \text{expit}(-1.346 + 1.346 X)$ where $\text{expit}(u) = \frac{\exp(u)}{\exp(u) + 1}.$

C.  According to the fitted model, what is the probability of D for individuals with X=0?  Why is this different from Q4C?

**Answer: **

According to the fitted model, the probability of $D$ when $X = 0$ is given by

$$P(D = 1 \mid X=0) = \frac{\exp(-1.346)}{\exp(-1.346) + 1} = 0.207 $$

This is different than what we obtained in question 4C, despite there being 10 diseased people out of 30 in group $X=0$ as before. In question 4 the data only had 3 values for $X$, and the fitted model was able to match the proportion of $D$ in every $X$ group. For the data in this question, the simple regression model is not able to match the proportion of D in every X group. Thus, the fitted model is influenced by the group at $X=-1$ with no disease in that group. 

D.  According to the fitted model, what is the probability of D for individuals with X=1?  How does this compare with Q4D?  Why does this make sense?

**Answer: **

According to the fitted model, the probability of $D$ when $X = 1$ is given by

$$P(D = 1 \mid X=1) = \frac{\exp(-1.346 + 1.346)}{\exp(-1.346 + 1.346) + 1} = 0.5$$

This is the same as what we obtained in question 4D. This makes sense because, despite not being able to match the proportion of D in every X group, the new data are added symmetrically, the group $X = 1$ being equally influenced by group $X=-1$ (with only non-diseased people) and group $X=3$ (with only diseased people). Hence, the fitted probability for people with $X=1$ did not change.

\pagebreak

## Code Appendix

```{r ref.label=knitr::all_labels(appendix == TRUE), echo=TRUE, eval=FALSE, include=TRUE}
```